{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "import fim\n",
    "from fim import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function apriori in module fim:\n",
      "\n",
      "apriori(...)\n",
      "    apriori (tracts, target='s', supp=10, zmin=1, zmax=None, report='a',\n",
      "             eval='x', agg='x', thresh=10, prune=None, algo='b', mode='',\n",
      "             border=None)\n",
      "    Find frequent item sets with the Apriori algorithm.\n",
      "    tracts  transaction database to mine (mandatory)\n",
      "            The database must be an iterable of transactions;\n",
      "            each transaction must be an iterable of items;\n",
      "            each item must be a hashable object.\n",
      "            If the database is a dictionary, the transactions are\n",
      "            the keys, the values their (integer) multiplicities.\n",
      "    target  type of frequent item sets to find     (default: s)\n",
      "            s/a   sets/all   all     frequent item sets\n",
      "            c     closed     closed  frequent item sets\n",
      "            m     maximal    maximal frequent item sets\n",
      "            g     gens       generators\n",
      "            r     rules      association rules\n",
      "    supp    minimum support of an item set         (default: 10)\n",
      "            (positive: percentage, negative: absolute number)\n",
      "    conf    minimum confidence of an assoc. rule   (default: 80%)\n",
      "    zmin    minimum number of items per item set   (default: 1)\n",
      "    zmax    maximum number of items per item set   (default: no limit)\n",
      "    report  values to report with an item set      (default: a)\n",
      "            a     absolute item set support (number of transactions)\n",
      "            s     relative item set support as a fraction\n",
      "            S     relative item set support as a percentage\n",
      "            e     value of item set evaluation measure\n",
      "            E     value of item set evaluation measure as a percentage\n",
      "            (     combine values in a tuple (must be first character)\n",
      "            [     combine values in a list  (must be first character)\n",
      "            #     pattern spectrum as a dictionary  (no patterns)\n",
      "            =     pattern spectrum as a list        (no patterns)\n",
      "            |     pattern spectrum as three columns (no patterns)\n",
      "            for target 'r' (association rules) also available:\n",
      "            b     absolute body set  support (number of transactions)\n",
      "            x     relative body set  support as a fraction\n",
      "            X     relative body set  support as a percentage\n",
      "            h     absolute head item support (number of transactions)\n",
      "            y     relative head item support as a fraction\n",
      "            Y     relative head item support as a percentage\n",
      "            c     rule confidence as a fraction\n",
      "            C     rule confidence as a percentage\n",
      "            l     lift value of a rule (confidence/prior)\n",
      "            L     lift value of a rule as a percentage\n",
      "            Q     support of the empty set (total number of transactions)\n",
      "    eval    measure for item set evaluation        (default: x)\n",
      "            x     none       no measure / zero (default)\n",
      "            b     ldratio    binary logarithm of support quotient       (+)\n",
      "            c     conf       rule confidence                            (+)\n",
      "            d     confdiff   absolute confidence difference to prior    (+)\n",
      "            l     lift       lift value (confidence divided by prior)   (+)\n",
      "            a     liftdiff   absolute difference of lift value to 1     (+)\n",
      "            q     liftquot   difference of lift quotient to 1           (+)\n",
      "            v     cvct       conviction (inverse lift for negated head) (+)\n",
      "            e     cvctdiff   absolute difference of conviction to 1     (+)\n",
      "            r     cvctquot   difference of conviction quotient to 1     (+)\n",
      "            k     cprob      conditional probability ratio              (+)\n",
      "            j     import     importance (binary log. of prob. ratio)    (+)\n",
      "            z     cert       certainty factor (relative conf. change)   (+)\n",
      "            n     chi2       normalized chi^2 measure                   (+)\n",
      "            p     chi2pval   p-value from (unnormalized) chi^2 measure  (-)\n",
      "            y     yates      normalized chi^2 with Yates' correction    (+)\n",
      "            t     yatespval  p-value from Yates-corrected chi^2 measure (-)\n",
      "            i     info       information difference to prior            (+)\n",
      "            g     infopval   p-value from G statistic/info. difference  (-)\n",
      "            f     fetprob    Fisher's exact test (table probability)    (-)\n",
      "            h     fetchi2    Fisher's exact test (chi^2 measure)        (-)\n",
      "            m     fetinfo    Fisher's exact test (mutual information)   (-)\n",
      "            s     fetsupp    Fisher's exact test (support)              (-)\n",
      "            Measures marked with (+) must meet or exceed the threshold,\n",
      "            measures marked with (-) must not exceed the threshold\n",
      "            in order for the item set to be reported.\n",
      "    agg     evaluation measure aggregation mode    (default: x)\n",
      "            x     none       no aggregation (use first value)\n",
      "            m     min        minimum of individual measure values\n",
      "            n     max        maximum of individual measure values\n",
      "            a     avg        average of individual measure values\n",
      "    thresh  threshold for evaluation measure       (default: 10%)\n",
      "    prune   min. size for evaluation filtering     (default: no pruning)\n",
      "            = 0   backward filtering       (no subset check)\n",
      "            < 0   weak   forward filtering (one subset  must qualify)\n",
      "            > 0   strong forward filtering (all subsets must qualify)\n",
      "    algo    algorithm variant to use               (default: a)\n",
      "            b     basic      standard algorithm (only choice)\n",
      "    mode    operation mode indicators/flags        (default: None)\n",
      "            x     do not use perfect extension pruning\n",
      "            t/T   do not organize transactions as a prefix tree\n",
      "            y     a-posteriori pruning of infrequent item sets\n",
      "            z     invalidate evaluation below expected support\n",
      "            o     use original rule support definition (body & head)\n",
      "    border  support border for filtering item sets (default: None)\n",
      "            Must be a list or tuple of (absolute) minimum support values\n",
      "            per item set size (by which the list/tuple is indexed).\n",
      "    appear  dictionary mapping items to item appearance indicators,\n",
      "            with the key None referring to the default item appearance.\n",
      "            (If None does not occur as a key or no dictionary is given,\n",
      "            the default item appearance indicator is 'both'.)\n",
      "            This parameter is only used if the target type is rules.\n",
      "            * item may not appear anywhere in a rule:\n",
      "              '-', 'n', 'none', 'neither', 'ignore'\n",
      "            * item may appear only in rule body/antecedent:\n",
      "              'i', 'in', 'inp', 'input', 'b', 'body',\n",
      "              'a', 'ante', 'antecedent'\n",
      "            * item may appear only in rule head/consequent:\n",
      "              'o', 'out',      'output', 'h', 'head',\n",
      "              'c', 'cons', 'consequent'\n",
      "            * item may appear anywhere in a rule:\n",
      "              'io', 'i&o', 'inout', 'in&out', 'bh', 'b&h', 'both'\n",
      "    returns if report is not in ['#','=','|']:\n",
      "              if the target is association rules:\n",
      "                a list of rules (i.e. tuples with two or more elements),\n",
      "                each consisting of a head/consequent item, a tuple with\n",
      "                a body/antecedent item set, and the values selected by\n",
      "                the parameter 'report', which may be combined into a\n",
      "                tuple or a list if report[0] is '(' or '[', respectively.          if the target is a type of item sets:\n",
      "                a list of patterns (i.e. tuples with one or more elements),\n",
      "                each consisting of a tuple with a found frequent item set\n",
      "                and the values selected by the parameter 'report', which\n",
      "                may be combined into a tuple or list if report[0] is '('\n",
      "                or '[', respectively\n",
      "            if report in ['#','=','|']:\n",
      "              a pattern spectrum as a dictionary mapping pattern sizes\n",
      "              to the corresponding occurrence support ranges, as a list\n",
      "              of triplets (size, min. support, max. support) or as three\n",
      "              columns for sizes and minimum and maximum support values\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fim.apriori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calling external C function\n",
    "\n",
    "import subprocess\n",
    "\n",
    "# Helper function to call 'apriori' from within a linux executable file\n",
    "def call_apriori(fileinput, fileoutput, delimiter=',', target_type='s', \n",
    "                 min_nbr_items=1, min_sup=2, min_conf=2):\n",
    "    # apriori\n",
    "    # -t# {m: maximal, c: closed, s: frequent, r: association rules}\n",
    "    # -m# minimum number of items per item set/association rule\n",
    "    # -s# minimum support of an item set, positive: percentage, negative: absolute\n",
    "    # -c# minimum confidence rule percentage\n",
    "    # -b# line delimiter (,)\n",
    "    # The default additional information output format for rules is \" (%X, %C)\"\n",
    "    # %X relative body set support as a percentage\n",
    "    # %C rule confidence as a percentage\n",
    "    # %L lift\n",
    "\n",
    "    if target_type == 'r':\n",
    "        call_cmd = ['./apriori', '-b%s' % delimiter, '-t%s' % target_type, '-m%s' % min_nbr_items, \n",
    "                    '-s%s' % min_sup, '-c%s' % min_conf, '-v (%X, %C, %L)', \n",
    "                    fileinput, fileoutput]\n",
    "    else:\n",
    "        call_cmd = ['./apriori', '-b%s' % delimiter, '-t%s' % target_type, \n",
    "                           '-m%s' % min_nbr_items, '-s%s' % min_sup, fileinput, fileoutput]\n",
    "\n",
    "    ret = subprocess.call(call_cmd,  stdout=open('apriori_stdout.txt', 'w'), \n",
    "                          stderr=open('apriori_stderr.txt', 'w'))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_freq_patterns(filename):\n",
    "    \n",
    "    data = open(filename, 'r')\n",
    "    freq_patterns = list()\n",
    "    \n",
    "    for row in data:\n",
    "        fields = row.rstrip('\\n\\r').split(' ')\n",
    "        \n",
    "        support = float(fields[len(fields) - 1].split('(')[1].split(')')[0])\n",
    "        freq_pattern = {\n",
    "            'itemset': fields[:len(fields) - 1],\n",
    "            'support': support\n",
    "        }\n",
    "        freq_patterns.append(freq_pattern)\n",
    "    data.close()\n",
    "    return freq_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to better visualize association rules returned by the call to 'apriori' (with target_type='r')\n",
    "\n",
    "def read_rules(filename):\n",
    "    data = open(filename, 'r')\n",
    "    rules = list()\n",
    "    for row in data:\n",
    "        fileds = row.rstrip('\\n\\r').split(' <- ')\n",
    "        cons = fileds[0]\n",
    "        other = fileds[1].split(' (')\n",
    "        ant = other[0].split(' ')\n",
    "        other2 = other[1].split(', ')\n",
    "        sup = float(other2[0])\n",
    "        conf = float(other2[1])\n",
    "        lift = float(other2[2].replace(')', ''))\n",
    "        rule = {\n",
    "            'ant': ant,\n",
    "            'cons': cons,\n",
    "            'sup': sup,\n",
    "            'conf': conf,\n",
    "            'lift': lift\n",
    "        }\n",
    "        rules.append(rule)\n",
    "    data.close()\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############### STARTING WITH ASSOCIATION RULES/FREQUENT PATTERNS MINING ON HR ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.88</td>\n",
       "      <td>7</td>\n",
       "      <td>272</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.72</td>\n",
       "      <td>0.87</td>\n",
       "      <td>5</td>\n",
       "      <td>223</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfaction_level  last_evaluation  number_project  average_montly_hours  \\\n",
       "0                0.38             0.53               2                   157   \n",
       "1                0.80             0.86               5                   262   \n",
       "2                0.11             0.88               7                   272   \n",
       "3                0.72             0.87               5                   223   \n",
       "4                0.37             0.52               2                   159   \n",
       "\n",
       "   time_spend_company  Work_accident  left  promotion_last_5years  sales  \\\n",
       "0                   3              0     1                      0  sales   \n",
       "1                   6              0     1                      0  sales   \n",
       "2                   4              0     1                      0  sales   \n",
       "3                   5              0     1                      0  sales   \n",
       "4                   3              0     1                      0  sales   \n",
       "\n",
       "   salary  \n",
       "0     low  \n",
       "1  medium  \n",
       "2  medium  \n",
       "3     low  \n",
       "4     low  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../HR.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### DISCRETIZATION OF NUMERICAL FEATURES ###############################\n",
    "\n",
    "# IMPORTANT: INTERVALS FOR BINS MAY BE CHOSEN BY LOOKING AT THE DISTRIBUTION OF THE FEATURE!\n",
    "# NOTE: WE MAY DISCUSS ON THE MOST APPROPRIATE NUMBER/WIDTH OF BINS FOR EACH SEPARATE FEATURE!\n",
    "\n",
    "# Discretize 'satisfaction_level'\n",
    "# (Moltiplico per 100 perché range(0, 1, 0.1) dà errore, visto che range() si aspetta parametri interi)\n",
    "\n",
    "df['satisfaction_level_group'] = pd.cut(df['satisfaction_level'] * 100, \n",
    "                                        bins=range(0, 125, 25), \n",
    "                                        right=False, \n",
    "                                        #labels=range(0, 120, 20)\n",
    "                                        labels=['very_low', 'low', 'medium', 'high'])\n",
    "\n",
    "# Discretize 'last_evaluation'\n",
    "df['last_evaluation_group'] = pd.cut(df['last_evaluation'] * 100, \n",
    "                                     bins=range(30, 130, 20), \n",
    "                                     right=False, \n",
    "                                     labels=range(30, 110, 20))\n",
    "\n",
    "# Discretize 'average_montly_hours'\n",
    "df['average_montly_hours_group'] = pd.cut(df['average_montly_hours'], \n",
    "                                          bins=range(90, 340, 30), \n",
    "                                          right=False, \n",
    "                                          labels=range(90, 320, 30))\n",
    "\n",
    "\n",
    "# \n",
    "# Question: shall we further discretize 'number_project' and 'time_spend_company'? \n",
    "# Even small bins would do, as I don't think leaving them as they are makes much sense\n",
    "# If we don't further discretize, we may end up getting sorts of 'duplicated' rules\n",
    "#     Answer: YES\n",
    "\n",
    "# Discretize 'number_project'\n",
    "df['number_project_group'] = pd.cut(df['number_project'], \n",
    "                                    bins=range(2, 12, 2),\n",
    "                                    right=False, \n",
    "                                    labels=range(2, 10, 2))\n",
    "\n",
    "# Discretize 'time_spend_company'\n",
    "df['time_spend_company_group'] = pd.cut(df['time_spend_company'], \n",
    "                                 bins=[2, 4, 7, 11], \n",
    "                                 right=False, \n",
    "                                 labels=['2_to_3', '4_to_6', '7_to_10'])\n",
    "\n",
    "\n",
    "df.drop(['satisfaction_level', 'last_evaluation', 'average_montly_hours', \n",
    "         'number_project', 'time_spend_company'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "      <th>satisfaction_level_group</th>\n",
       "      <th>last_evaluation_group</th>\n",
       "      <th>average_montly_hours_group</th>\n",
       "      <th>number_project_group</th>\n",
       "      <th>time_spend_company_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>2_to_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>70</td>\n",
       "      <td>240</td>\n",
       "      <td>4</td>\n",
       "      <td>4_to_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "      <td>very_low</td>\n",
       "      <td>70</td>\n",
       "      <td>270</td>\n",
       "      <td>6</td>\n",
       "      <td>4_to_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>70</td>\n",
       "      <td>210</td>\n",
       "      <td>4</td>\n",
       "      <td>4_to_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>2</td>\n",
       "      <td>2_to_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Work_accident  left  promotion_last_5years  sales  salary  \\\n",
       "0              0     1                      0  sales     low   \n",
       "1              0     1                      0  sales  medium   \n",
       "2              0     1                      0  sales  medium   \n",
       "3              0     1                      0  sales     low   \n",
       "4              0     1                      0  sales     low   \n",
       "\n",
       "  satisfaction_level_group last_evaluation_group average_montly_hours_group  \\\n",
       "0                      low                    50                        150   \n",
       "1                     high                    70                        240   \n",
       "2                 very_low                    70                        270   \n",
       "3                   medium                    70                        210   \n",
       "4                      low                    50                        150   \n",
       "\n",
       "  number_project_group time_spend_company_group  \n",
       "0                    2                   2_to_3  \n",
       "1                    4                   4_to_6  \n",
       "2                    6                   4_to_6  \n",
       "3                    4                   4_to_6  \n",
       "4                    2                   2_to_3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2['Work_accident'] = df['Work_accident'].astype(str) + '_WA'\n",
    "df2['left'] = df['left'].astype(str) + '_L'\n",
    "df2['promotion_last_5years'] = df['promotion_last_5years'].astype(str) + '_PL5'\n",
    "df2['satisfaction_level_group'] = df['satisfaction_level_group'].astype(str) + '_SAT'\n",
    "df2['salary'] = df['salary'].astype(str) + '_SAL'\n",
    "df2['last_evaluation_group'] = df['last_evaluation_group'].astype(str) + '_LE'\n",
    "df2['average_montly_hours_group'] = df['average_montly_hours_group'].astype(str) + '_AMH'\n",
    "df2['number_project_group'] = df['number_project_group'].astype(str) + '_NP'\n",
    "df2['time_spend_company_group'] = df['time_spend_company_group'].astype(str) + '_TSC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "      <th>satisfaction_level_group</th>\n",
       "      <th>last_evaluation_group</th>\n",
       "      <th>average_montly_hours_group</th>\n",
       "      <th>number_project_group</th>\n",
       "      <th>time_spend_company_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_WA</td>\n",
       "      <td>1_L</td>\n",
       "      <td>0_PL5</td>\n",
       "      <td>sales</td>\n",
       "      <td>low_SAL</td>\n",
       "      <td>low_SAT</td>\n",
       "      <td>50_LE</td>\n",
       "      <td>150_AMH</td>\n",
       "      <td>2_NP</td>\n",
       "      <td>2_to_3_TSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_WA</td>\n",
       "      <td>1_L</td>\n",
       "      <td>0_PL5</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium_SAL</td>\n",
       "      <td>high_SAT</td>\n",
       "      <td>70_LE</td>\n",
       "      <td>240_AMH</td>\n",
       "      <td>4_NP</td>\n",
       "      <td>4_to_6_TSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_WA</td>\n",
       "      <td>1_L</td>\n",
       "      <td>0_PL5</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium_SAL</td>\n",
       "      <td>very_low_SAT</td>\n",
       "      <td>70_LE</td>\n",
       "      <td>270_AMH</td>\n",
       "      <td>6_NP</td>\n",
       "      <td>4_to_6_TSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_WA</td>\n",
       "      <td>1_L</td>\n",
       "      <td>0_PL5</td>\n",
       "      <td>sales</td>\n",
       "      <td>low_SAL</td>\n",
       "      <td>medium_SAT</td>\n",
       "      <td>70_LE</td>\n",
       "      <td>210_AMH</td>\n",
       "      <td>4_NP</td>\n",
       "      <td>4_to_6_TSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_WA</td>\n",
       "      <td>1_L</td>\n",
       "      <td>0_PL5</td>\n",
       "      <td>sales</td>\n",
       "      <td>low_SAL</td>\n",
       "      <td>low_SAT</td>\n",
       "      <td>50_LE</td>\n",
       "      <td>150_AMH</td>\n",
       "      <td>2_NP</td>\n",
       "      <td>2_to_3_TSC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Work_accident left promotion_last_5years  sales      salary  \\\n",
       "0          0_WA  1_L                 0_PL5  sales     low_SAL   \n",
       "1          0_WA  1_L                 0_PL5  sales  medium_SAL   \n",
       "2          0_WA  1_L                 0_PL5  sales  medium_SAL   \n",
       "3          0_WA  1_L                 0_PL5  sales     low_SAL   \n",
       "4          0_WA  1_L                 0_PL5  sales     low_SAL   \n",
       "\n",
       "  satisfaction_level_group last_evaluation_group average_montly_hours_group  \\\n",
       "0                  low_SAT                 50_LE                    150_AMH   \n",
       "1                 high_SAT                 70_LE                    240_AMH   \n",
       "2             very_low_SAT                 70_LE                    270_AMH   \n",
       "3               medium_SAT                 70_LE                    210_AMH   \n",
       "4                  low_SAT                 50_LE                    150_AMH   \n",
       "\n",
       "  number_project_group time_spend_company_group  \n",
       "0                 2_NP               2_to_3_TSC  \n",
       "1                 4_NP               4_to_6_TSC  \n",
       "2                 6_NP               4_to_6_TSC  \n",
       "3                 4_NP               4_to_6_TSC  \n",
       "4                 2_NP               2_to_3_TSC  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('hr_for_pattern_mining.csv', sep=',', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "############## FREQUENT ITEMSETS ##############\n",
    "###############################################\n",
    "\n",
    "delimiter=','\n",
    "target_type='s' # Meaning that I want frequent itemsets\n",
    "min_nbr_items=3\n",
    "min_sup=10\n",
    "min_conf=100 # Meaningless here\n",
    "\n",
    "\n",
    "ret_val = call_apriori('hr_for_pattern_mining.csv', \n",
    "                       'Frequent/frequent_patterns.txt', \n",
    "                       delimiter, target_type, min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "############### CLOSED ITEMSETS ###############\n",
    "###############################################\n",
    "\n",
    "delimiter=','\n",
    "target_type='c' # Meaning that I want closed frequent itemsets\n",
    "min_nbr_items=3\n",
    "min_sup=10\n",
    "min_conf=100 # Meaningless here\n",
    "\n",
    "\n",
    "ret_val = call_apriori('hr_for_pattern_mining.csv', \n",
    "                       'Closed/closed_patterns.txt', \n",
    "                       delimiter, target_type, min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "############### MAXIMAL ITEMSETS ##############\n",
    "###############################################\n",
    "\n",
    "delimiter=','\n",
    "target_type='m' # Meaning that I want maximal frequent itemsets\n",
    "min_nbr_items=2\n",
    "min_sup=10\n",
    "min_conf=100 # Meaningless here\n",
    "\n",
    "\n",
    "ret_val = call_apriori('hr_for_pattern_mining.csv', \n",
    "                       'Maximal/maximal_patterns.txt', \n",
    "                       delimiter, target_type, min_nbr_items, min_sup, min_conf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_freq_patterns(filename, freq_pts):\n",
    "    \n",
    "    f = open(filename, 'w')\n",
    "    for pt in sorted(freq_pts, key=lambda p: p['support'], reverse=True):\n",
    "        f.write('{} support = {}\\n'.format(pt['itemset'], pt['support']))\n",
    "        \n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Obtaining frequent itemsets with different values of support\n",
    "\n",
    "freq_patterns = read_freq_patterns('Frequent/frequent_patterns.txt')\n",
    "previous_min_sup = 101;\n",
    "\n",
    "for min_sup in [50, 40, 30, 20, 10]:    \n",
    "    pts = [fp for fp in freq_patterns \n",
    "           if fp['support'] >= min_sup \n",
    "           and fp['support'] < previous_min_sup]    \n",
    "    write_freq_patterns('Frequent/freq_{}_to_{}_sup.txt'.format(min_sup, previous_min_sup), pts)\n",
    "    previous_min_sup = min_sup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtaining closed itemsets with different values of support\n",
    "\n",
    "freq_patterns = read_freq_patterns('Closed/closed_patterns.txt')\n",
    "previous_min_sup = 101;\n",
    "\n",
    "for min_sup in [50, 40, 30, 20, 10]:    \n",
    "    pts = [fp for fp in freq_patterns \n",
    "           if fp['support'] >= min_sup \n",
    "           and fp['support'] < previous_min_sup]    \n",
    "    write_freq_patterns('Closed/closed_{}_to_{}_sup.txt'.format(min_sup, previous_min_sup), pts)\n",
    "    previous_min_sup = min_sup\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtaining maximal itemsets with different values of support\n",
    "\n",
    "freq_patterns = read_freq_patterns('Maximal/maximal_patterns.txt')\n",
    "previous_min_sup = 101;\n",
    "\n",
    "for min_sup in [20, 15, 10]:    \n",
    "    pts = [fp for fp in freq_patterns \n",
    "           if fp['support'] >= min_sup \n",
    "           and fp['support'] < previous_min_sup]    \n",
    "    write_freq_patterns('Maximal/maximal_{}_to_{}_sup.txt'.format(min_sup, previous_min_sup), pts)\n",
    "    previous_min_sup = min_sup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "############## ASSOCIATION RULES ##############\n",
    "###############################################\n",
    "\n",
    "delimiter=','\n",
    "target_type='r' # Meaning that I want association rules\n",
    "min_nbr_items=3\n",
    "min_sup=5\n",
    "min_conf=70\n",
    "\n",
    "\n",
    "ret_val = call_apriori('hr_for_pattern_mining.csv', \n",
    "                       'Rules/association_rules.txt', \n",
    "                       delimiter, target_type, min_nbr_items, min_sup, min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_rules(filename, assoc_rules):\n",
    "    \n",
    "    f = open(filename, 'w')\n",
    "    for rl in sorted(assoc_rules, key=lambda r: (r['lift'], r['conf']), reverse=True):\n",
    "        f.write('{} -> {}, lift = {}, confidence = {}\\n'.format(rl['ant'], rl['cons'], rl['lift'], rl['conf']))\n",
    "        \n",
    "    f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assoc_rules = read_rules('Rules/association_rules.txt')\n",
    "\n",
    "# Rules whose consequences tell me something about the 'left' attribute\n",
    "rls_left_true = [rl for rl in assoc_rules if rl['cons'].endswith('1_L')]\n",
    "rls_left_false = [rl for rl in assoc_rules if rl['cons'].endswith('0_L') and rl['sup'] > 20]\n",
    "\n",
    "# Rules whose consequences tell me something about an attribute that is not 'left'\n",
    "rls_other = [rl for rl in assoc_rules if not(rl['cons'].endswith('_L')) and rl['sup'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtaining association rules with different values of confidence\n",
    "\n",
    "# RULES TELLING SOMETHING ABOUT 'left', IN PARTICULAR left=1\n",
    "previous_min_conf = 101;\n",
    "for min_conf in [90, 80, 70]:    \n",
    "    rls = [rl for rl in rls_left_true\n",
    "           if rl['conf'] >= min_conf \n",
    "           and rl['conf'] < previous_min_conf]  \n",
    "    write_rules('Rules/Rules_about_left/Rules_left_true/rules_{}_to_{}_conf.txt'\n",
    "                .format(min_conf, previous_min_conf), rls)\n",
    "    previous_min_conf = min_conf\n",
    "    \n",
    "# RULES TELLING SOMETHING ABOUT 'left', IN PARTICULAR left=0\n",
    "previous_min_conf = 101;\n",
    "for min_conf in [90, 80, 70]:    \n",
    "    rls = [rl for rl in rls_left_false\n",
    "           if rl['conf'] >= min_conf \n",
    "           and rl['conf'] < previous_min_conf]  \n",
    "    write_rules('Rules/Rules_about_left/Rules_left_false/rules_{}_to_{}_conf.txt'\n",
    "                .format(min_conf, previous_min_conf), rls)\n",
    "    previous_min_conf = min_conf    \n",
    "    \n",
    "# GENERAL RULES    \n",
    "previous_min_conf = 101;\n",
    "for min_conf in [90, 80, 70]:    \n",
    "    rls = [rl for rl in rls_other\n",
    "           if rl['conf'] >= min_conf \n",
    "           and rl['conf'] < previous_min_conf]  \n",
    "    write_rules('Rules/Rules_not_about_left/rules_{}_to_{}_conf.txt'.format(min_conf, previous_min_conf), rls)\n",
    "    previous_min_conf = min_conf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# USING THE MOST MEANINGFUL RULES TO PREDICT (ARTIFICIAL) MISSING VALUES #\n",
    "##########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735413839891451"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target_attr = 'promotion_last_5years'\n",
    "\n",
    "# I randomly take 5% of the rows and try to predict the feature 'promotion_last_5years'\n",
    "subset = df2.sample(frac=0.1).reset_index(drop=True)\n",
    "\n",
    "# I sort the rules according to the confidence value, then I extract a bunch of them\n",
    "conf_sorted_rules = sorted(rls_other, key=lambda r: (r['conf'], r['lift']), reverse=True)\n",
    "rules_pool = conf_sorted_rules[:15]\n",
    "\n",
    "affected_rows = 0\n",
    "correctly_guessed = 0\n",
    "for i in range(len(subset.index)):\n",
    "    df_row = subset.iloc[[i]] # Fetch i-th row\n",
    "    rule = list() # Empty list\n",
    "    for r in rules_pool:\n",
    "        if set(r['ant']) < set(df_row.values[0]):\n",
    "            rule = r\n",
    "            break\n",
    "    if rule: # If I found a rule\n",
    "        affected_rows = affected_rows + 1\n",
    "        if rule['cons'] == df_row[target_attr].values[0]:\n",
    "            correctly_guessed = correctly_guessed + 1\n",
    "            \n",
    "accuracy = correctly_guessed / float(affected_rows)\n",
    "accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# USING THE MOST MEANINGFUL RULES TO PREDICT IF AN EMPLOYEE WILL LEAVE OR NOT #\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972880983750549"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I sort the rules according to the confidence value, then I extract a bunch of them\n",
    "rls_left_true_sorted = sorted(rls_left_true, key=lambda r: (r['conf'], r['lift']), reverse=True)\n",
    "rls_left_false_sorted = sorted(rls_left_false, key=lambda r: (r['conf'], r['lift']), reverse=True)\n",
    "rules_pool = rls_left_true_sorted[:5] + rls_left_false_sorted[:5]\n",
    "\n",
    "affected_rows = 0\n",
    "correctly_guessed = 0\n",
    "for i in range(len(df2.index)):\n",
    "    emp = df2.iloc[[i]] # Fetch i-th row\n",
    "    rule = list() # Empty list\n",
    "    for r in rules_pool:\n",
    "        if set(r['ant']) < set(emp.values[0]):\n",
    "            rule = r\n",
    "            break\n",
    "    if rule: # If I found a rule\n",
    "        affected_rows = affected_rows + 1\n",
    "        if rule['cons'] == emp['left'].values[0]:\n",
    "            correctly_guessed = correctly_guessed + 1\n",
    "            \n",
    "accuracy = correctly_guessed / float(affected_rows)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# THE CODE BELOW CAN BE IGNORED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accounting', '0_PL5'] --> 0_L  lift 95.6906  conf 72.9084\n",
      "['accounting', '0_PL5'] --> 0_WA  lift 102.157  conf 87.3838\n",
      "['RandD', '0_PL5'] --> 0_L  lift 110.352  conf 84.0789\n"
     ]
    }
   ],
   "source": [
    "rules = read_rules('Rules/association_rules.txt')\n",
    "for r in rules[:3]:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect those rules whose consequences tell something about the 'left' attribute\n",
    "rules_cons_L = list()\n",
    "for r in rules:\n",
    "    if r['cons'].endswith('_L'):\n",
    "        rules_cons_L.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_rules_cons_L = sorted(rules_cons_L, key=lambda r: r['conf'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['180_AMH', '4_NP', '2_to_3_TSC'] --> 0_L  lift 130.935  conf 99.7613\n",
      "['180_AMH', '4_NP', '2_to_3_TSC', '0_PL5'] --> 0_L  lift 130.928  conf 99.7567\n",
      "['80_SL', '4_NP', '2_to_3_TSC'] --> 0_L  lift 130.904  conf 99.7382\n",
      "['80_SL', '4_NP', '2_to_3_TSC', '0_PL5'] --> 0_L  lift 130.892  conf 99.7292\n",
      "['80_SL', '4_NP', '2_to_3_TSC', '0_WA'] --> 0_L  lift 130.834  conf 99.6848\n",
      "['80_SL', '4_NP', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L  lift 130.82  conf 99.6737\n",
      "['60_SL', '4_NP', '2_to_3_TSC', '0_PL5'] --> 0_L  lift 130.75  conf 99.621\n",
      "['80_SL', 'low', '2_to_3_TSC', '0_WA'] --> 0_L  lift 130.746  conf 99.6176\n",
      "['80_SL', 'low', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L  lift 130.741  conf 99.6139\n",
      "['80_SL', 'low', '2_to_3_TSC'] --> 0_L  lift 130.733  conf 99.6075\n"
     ]
    }
   ],
   "source": [
    "for r in sorted_rules_cons_L[:10]:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_SL', '6_NP', '4_to_6_TSC', '0_WA'] --> 1_L  lift 395.143  conf 94.0767\n",
      "['0_SL', '6_NP', '4_to_6_TSC', '0_WA', '0_PL5'] --> 1_L  lift 395.056  conf 94.0559\n",
      "['0_SL', '6_NP', '4_to_6_TSC', '0_PL5'] --> 1_L  lift 388.705  conf 92.5439\n",
      "['0_SL', '6_NP', '4_to_6_TSC'] --> 1_L  lift 387.96  conf 92.3664\n",
      "['0_SL', '6_NP', '0_WA', '0_PL5'] --> 1_L  lift 379.465  conf 90.3441\n",
      "['0_SL', '6_NP', '0_WA'] --> 1_L  lift 377.928  conf 89.978\n",
      "['0_SL', '6_NP', '0_PL5'] --> 1_L  lift 372.332  conf 88.6458\n",
      "['0_SL', '6_NP'] --> 1_L  lift 370.175  conf 88.1321\n",
      "['120_AMH', '40_SL', '2_NP', '2_to_3_TSC', '0_PL5'] --> 1_L  lift 343.124  conf 81.6919\n",
      "['120_AMH', '40_SL', '2_NP', '2_to_3_TSC'] --> 1_L  lift 341.695  conf 81.3517\n",
      "['120_AMH', '40_SL', '2_NP', '0_WA', '0_PL5'] --> 1_L  lift 333.531  conf 79.408\n",
      "['120_AMH', '40_SL', '2_NP', '0_WA'] --> 1_L  lift 332.161  conf 79.0816\n",
      "['6_NP', '4_to_6_TSC', '0_WA', '0_PL5'] --> 1_L  lift 328.021  conf 78.0961\n",
      "['6_NP', '4_to_6_TSC', '0_WA'] --> 1_L  lift 327.672  conf 78.0129\n",
      "['120_AMH', '40_SL', '2_NP', '0_PL5'] --> 1_L  lift 322.749  conf 76.8409\n",
      "['120_AMH', '2_NP', 'low', '2_to_3_TSC', '0_WA', '0_PL5'] --> 1_L  lift 322.547  conf 76.7927\n",
      "['120_AMH', '50_LE', '2_NP', '2_to_3_TSC', '0_WA', '0_PL5'] --> 1_L  lift 322.017  conf 76.6667\n",
      "['120_AMH', '2_NP', 'low', '2_to_3_TSC', '0_WA'] --> 1_L  lift 321.963  conf 76.6537\n",
      "['120_AMH', '50_LE', '2_NP', '2_to_3_TSC', '0_WA'] --> 1_L  lift 321.32  conf 76.5006\n",
      "['120_AMH', '40_SL', '2_NP'] --> 1_L  lift 320.064  conf 76.2016\n",
      "['20_SL', '2_NP', '2_to_3_TSC', '0_PL5'] --> 1_L  lift 319.061  conf 75.9628\n",
      "['0_SL', '4_to_6_TSC', '0_WA', '0_PL5'] --> 1_L  lift 318.278  conf 75.7764\n",
      "['0_SL', '4_to_6_TSC', '0_WA'] --> 1_L  lift 317.985  conf 75.7067\n",
      "['20_SL', '2_NP', '2_to_3_TSC'] --> 1_L  lift 317.375  conf 75.5614\n",
      "['6_NP', '4_to_6_TSC', '0_PL5'] --> 1_L  lift 314.839  conf 74.9576\n",
      "['6_NP', '4_to_6_TSC'] --> 1_L  lift 313.249  conf 74.5791\n",
      "['120_AMH', '40_SL', '2_to_3_TSC', '0_WA', '0_PL5'] --> 1_L  lift 312.131  conf 74.313\n",
      "['120_AMH', '40_SL', '2_to_3_TSC', '0_WA'] --> 1_L  lift 311.774  conf 74.228\n",
      "['120_AMH', '50_LE', '2_NP', '2_to_3_TSC', '0_PL5'] --> 1_L  lift 310.408  conf 73.9027\n",
      "['120_AMH', '2_NP', 'low', '2_to_3_TSC', '0_PL5'] --> 1_L  lift 309.861  conf 73.7725\n",
      "['120_AMH', '50_LE', '2_NP', '2_to_3_TSC'] --> 1_L  lift 309.804  conf 73.7589\n",
      "['120_AMH', '2_NP', 'low', '2_to_3_TSC'] --> 1_L  lift 309.385  conf 73.6591\n",
      "['0_SL', '4_to_6_TSC', '0_PL5'] --> 1_L  lift 305.904  conf 72.8305\n",
      "['0_SL', '4_to_6_TSC'] --> 1_L  lift 304.948  conf 72.6027\n",
      "['120_AMH', '2_NP', 'low', '0_WA', '0_PL5'] --> 1_L  lift 302.05  conf 71.9128\n",
      "['120_AMH', '50_LE', '2_NP', '0_WA', '0_PL5'] --> 1_L  lift 301.954  conf 71.89\n",
      "['120_AMH', '2_NP', 'low', '0_WA'] --> 1_L  lift 301.244  conf 71.7208\n",
      "['120_AMH', '50_LE', '2_NP', '0_WA'] --> 1_L  lift 301.016  conf 71.6667\n",
      "['120_AMH', '40_SL', '2_to_3_TSC', '0_PL5'] --> 1_L  lift 300.939  conf 71.6484\n",
      "['120_AMH', '40_SL', '2_to_3_TSC'] --> 1_L  lift 299.689  conf 71.3508\n",
      "['0_SL', 'low'] --> 1_L  lift 298.925  conf 71.1688\n",
      "['120_AMH', '2_NP', '2_to_3_TSC', '0_WA', '0_PL5'] --> 1_L  lift 298.696  conf 71.1144\n",
      "['0_SL', 'low', '0_PL5'] --> 1_L  lift 298.451  conf 71.0561\n",
      "['120_AMH', '2_NP', '2_to_3_TSC', '0_WA'] --> 1_L  lift 297.873  conf 70.9184\n",
      "['6_NP', 'low'] --> 1_L  lift 296.773  conf 70.6564\n",
      "['6_NP', 'low', '0_PL5'] --> 1_L  lift 296.678  conf 70.6339\n",
      "['90_LE', '4_to_6_TSC', '4_NP', '0_WA', '0_PL5'] --> 1_L  lift 296.142  conf 70.5063\n",
      "['90_LE', '4_to_6_TSC', '4_NP', '0_WA'] --> 1_L  lift 294.28  conf 70.0629\n",
      "['90_LE', '4_to_6_TSC', 'low', '0_PL5'] --> 1_L  lift 294.016  conf 70.0\n"
     ]
    }
   ],
   "source": [
    "rules_did_leave = list()\n",
    "for r in rules:\n",
    "    if r['cons'].endswith('1_L'):\n",
    "        rules_did_leave.append(r)\n",
    "        \n",
    "sorted_rules_did_leave = sorted(rules_did_leave, key=lambda r: r['conf'], reverse=True)\n",
    "\n",
    "for r in sorted_rules_did_leave:\n",
    "    print r['ant'], '-->', r['cons'], ' lift', r['lift'], ' conf', r['conf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0_WA', '1_L', '0_PL5', 'sales', 'low', '20_SL', '50_LE', '150_AMH',\n",
       "       '2_NP', '2_to_3_TSC'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "employee_test = df2.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20_SL', '2_NP', '2_to_3_TSC', '0_PL5'] --> 1_L\n",
      "['20_SL', '2_NP', '2_to_3_TSC'] --> 1_L\n",
      "['150_AMH', 'sales', '0_PL5'] --> 0_L\n",
      "['150_AMH', 'sales'] --> 0_L\n",
      "['150_AMH', '50_LE', '0_WA', '0_PL5'] --> 0_L\n",
      "['150_AMH', '50_LE', '0_WA'] --> 0_L\n",
      "['150_AMH', '50_LE', '0_PL5'] --> 0_L\n",
      "['150_AMH', '50_LE'] --> 0_L\n",
      "['150_AMH', 'low', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['150_AMH', 'low', '2_to_3_TSC'] --> 0_L\n",
      "['150_AMH', 'low', '0_WA', '0_PL5'] --> 0_L\n",
      "['150_AMH', 'low', '0_WA'] --> 0_L\n",
      "['150_AMH', 'low', '0_PL5'] --> 0_L\n",
      "['150_AMH', 'low'] --> 0_L\n",
      "['150_AMH', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['150_AMH', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['150_AMH', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['150_AMH', '2_to_3_TSC'] --> 0_L\n",
      "['150_AMH', '0_WA', '0_PL5'] --> 0_L\n",
      "['150_AMH', '0_WA'] --> 0_L\n",
      "['150_AMH', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE', 'low', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE', 'low'] --> 0_L\n",
      "['sales', '50_LE', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['sales', '50_LE', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE', '2_to_3_TSC'] --> 0_L\n",
      "['sales', '50_LE', '0_WA', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE', '0_WA'] --> 0_L\n",
      "['sales', '50_LE', '0_PL5'] --> 0_L\n",
      "['sales', '50_LE'] --> 0_L\n",
      "['sales', '2_NP', '0_PL5'] --> 0_L\n",
      "['sales', '2_NP'] --> 0_L\n",
      "['sales', 'low', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['sales', 'low', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['sales', 'low', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['sales', 'low', '2_to_3_TSC'] --> 0_L\n",
      "['sales', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['sales', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['sales', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['sales', '2_to_3_TSC'] --> 0_L\n",
      "['sales', '0_WA', '0_PL5'] --> 0_L\n",
      "['sales', '0_WA'] --> 0_L\n",
      "['sales', '0_PL5'] --> 0_L\n",
      "['50_LE', 'low', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['50_LE', 'low', '2_to_3_TSC'] --> 0_L\n",
      "['50_LE', 'low', '0_WA', '0_PL5'] --> 0_L\n",
      "['50_LE', 'low', '0_WA'] --> 0_L\n",
      "['50_LE', 'low', '0_PL5'] --> 0_L\n",
      "['50_LE', 'low'] --> 0_L\n",
      "['50_LE', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['50_LE', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['50_LE', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['50_LE', '2_to_3_TSC'] --> 0_L\n",
      "['50_LE', '0_WA', '0_PL5'] --> 0_L\n",
      "['50_LE', '0_WA'] --> 0_L\n",
      "['50_LE', '0_PL5'] --> 0_L\n",
      "['2_NP', '0_WA', '0_PL5'] --> 0_L\n",
      "['2_NP', '0_WA'] --> 0_L\n",
      "['2_NP', '0_PL5'] --> 0_L\n",
      "['low', '2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['low', '2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['low', '2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['low', '2_to_3_TSC'] --> 0_L\n",
      "['low', '0_PL5'] --> 0_L\n",
      "['2_to_3_TSC', '0_WA', '0_PL5'] --> 0_L\n",
      "['2_to_3_TSC', '0_WA'] --> 0_L\n",
      "['2_to_3_TSC', '0_PL5'] --> 0_L\n",
      "['0_WA', '0_PL5'] --> 0_L\n"
     ]
    }
   ],
   "source": [
    "for r in rules:\n",
    "    if set(r['ant']) < set(employee_test) and r['cons'].endswith('_L'):\n",
    "        print r['ant'], '-->', r['cons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hr_baskets_list = list()\n",
    "for row in df2.values:\n",
    "    hr_baskets_list.append(list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rules = apriori(hr_baskets_list, supp=5, zmin=2, target='r', conf=80, report='ascl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1_L', ('0_SL', '6_NP', '4_to_6_TSC', '0_WA', '0_PL5'), 807, 0.05380358690579372, 0.9405594405594405, 3.950560360949608)\n",
      "('1_L', ('0_SL', '6_NP', '4_to_6_TSC', '0_WA'), 810, 0.054003600240016, 0.9407665505226481, 3.951430269193279)\n",
      "('1_L', ('0_SL', '6_NP', '4_to_6_TSC', '0_PL5'), 844, 0.05627041802786852, 0.9254385964912281, 3.887049428387547)\n",
      "('1_L', ('0_SL', '6_NP', '4_to_6_TSC'), 847, 0.0564704313620908, 0.9236641221374046, 3.8795962385715295)\n",
      "('1_L', ('0_SL', '6_NP', '0_WA', '0_PL5'), 814, 0.05427028468564571, 0.9034406215316315, 3.794653005419474)\n",
      "('1_L', ('0_SL', '6_NP', '0_WA'), 817, 0.05447029801986799, 0.8997797356828194, 3.7792764647176162)\n",
      "('1_L', ('0_SL', '6_NP', '0_PL5'), 851, 0.05673711580772051, 0.8864583333333333, 3.7233235904975266)\n",
      "('1_L', ('0_SL', '6_NP'), 854, 0.056937129141942794, 0.8813209494324046, 3.701745427201522)\n",
      "('1_L', ('120_AMH', '40_SL', '2_NP', '2_to_3_TSC', '0_PL5'), 647, 0.04313620908060537, 0.8169191919191919, 3.431243617921019)\n",
      "('1_L', ('120_AMH', '40_SL', '2_NP', '2_to_3_TSC'), 650, 0.04333622241482765, 0.8135168961201502, 3.4169532133593203)\n"
     ]
    }
   ],
   "source": [
    "for rule in rules:\n",
    "    if rule[0] == '1_L': # i.e. If left=1 is the consequence of this association rule\n",
    "        print rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
